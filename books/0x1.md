## Pyhacker 之 Url采集

**00x1：**  

需要用到的模块如下：  

import requests  

import re  

本文将用re正则进行讲解，如果你用Xpath也可以  

**00x2：**  

首先我们要选取搜索引擎（其他搜索引擎原理相同）  

以bing为例：Cn.bing.com  

首先分析bing翻页机制：  

https://cn.bing.com/search?q=小陈&first=0 第一页  

https://cn.bing.com/search?q=小陈&first=10 第二页  

https://cn.bing.com/search?q=小陈&first=20 第三页  

页数 = First*10  

分析完毕，我们来请求看一下  

```
def req():
    url = 'https://cn.bing.com/search?q=小陈&first=0'
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:60.0) Gecko/20100101 Firefox/60.0'}
    req = requests.get(url,headers=headers)
    html = req.content
    print html
```  

![img](https://github.com/hackxc/Pyhacker/blob/master/books/img/1/1.png)  

Ok，没毛病  

**00x3：**  

分析需要采集的url在哪个位置  

![img](https://github.com/hackxc/Pyhacker/blob/master/books/img/1/2.png)  

得出正则：<cite>(.*?)</cite>  

正则表达式学习：（百度搜：python 正则表达式）  

```
def reurl():
    urlr = r'<cite>(.*?)</cite>'
    reurl = re.findall(urlr,html)
    print reurl
```  

![img](https://github.com/hackxc/Pyhacker/blob/master/books/img/1/3.png)  

就在我请求第二页的时候发现了问题  

![img](https://github.com/hackxc/Pyhacker/blob/master/books/img/1/4.png)  

可以看到请求内容和第一页一样，有某种验证机制  

一般情况下验证机制，表示特定参数  

经过多次测试，发现缺少 Cookie: _EDGE_V=1;  

![img](https://github.com/hackxc/Pyhacker/blob/master/books/img/1/5.png)  

![img](https://github.com/hackxc/Pyhacker/blob/master/books/img/1/6.png)  

请求正常，大致已经完成  

接下来只需要给关键词和页数变量就ok了  

**00x5：**  

再搜索site:baidu.com 又出现了问题  

![img](https://github.com/hackxc/Pyhacker/blob/master/books/img/1/7.png)  

于是修改正则为：  

```'target="_blank" href="(http.*?\..*?\..*?)" h="'```  

![img](https://github.com/hackxc/Pyhacker/blob/master/books/img/1/8.png)  

有很多我们不想要的结果，我们再来遍历下采集的urls  

做一下处理  

正则为：(http[s]?://.*?)/  

```
def url():
    for url in urls:
        urlr = r'(http[s]?://.*?)/'
        url = re.findall(urlr,url)
        print url
```  

![img](https://github.com/hackxc/Pyhacker/blob/master/books/img/1/9.png)  

Print url 改为 print url[0] 再进行处理一下  

可以看到下面还有重复的url，对url去重一下  


```
def qc():#去重复
    for url in url_ok:
        if url in url_bing:
            continue
        url_bing.append(url)
```  

![img](https://github.com/hackxc/Pyhacker/blob/master/books/img/1/10.png)  

**00x6：**  

接下来我们要让他自动保存到url_bing.txt  


```
with open('url_bing.txt','a+')as f:
    for url in url_bing:
        print url
        f.write(url+"\n")
    print "Save as url_bing.txt"
```  

**00x7：**  

完整代码：/books/config/1.[Pyhacker]Url采集  

```
#!/usr/bin/python
#-*- coding:utf-8 -*-
import requests
import re

urls = []
url_ok = []
url_bing=[]

def req(q,first):
    global html
    url = 'https://cn.bing.com/search?q=%s&first=%s'%(q,first)
    print url
    headers = {
        'Host':'cn.bing.com',
        'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3314.0 Safari/537.36 SE 2.X MetaSr 1.0',
        'Cookie': '_EDGE_V=1;'
    }
    req = requests.get(url,headers=headers)
    html = req.content

def reurl():#正则匹配url
    urlr = r'target="_blank" href="(http.*?\..*?\..*?)" h="'
    reurl = re.findall(urlr,html)
    for url in reurl:
        if url not in urls:
            urls.append(url)

def url():#url二次处理
    for url in urls:
        urlr = r'(http[s]?://.*?)/'
        url = re.findall(urlr,url)
        url_ok.append(url[0])

def qc():#去重复
    for url in url_ok:
        if url in url_bing:
            continue
        url_bing.append(url)

if __name__ == '__main__':
    q = raw_input('\nkey:')
    page = input('page:')
    for first in range(0, page):
        req(q, first * 10)
        reurl()
    url()
    qc()
    with open('url_bing.txt','a+')as f:
        for url in url_bing:
            print url
            f.write(url+"\n")
        print "Save as url_bing.txt"
```